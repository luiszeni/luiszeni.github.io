<!DOCTYPE html>
<html lang="en">
<head>
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124421878-1"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'UA-124421878-1');
	</script>


	<link rel="stylesheet" href="../lib/bootstrap.min.css">
	<script src="../lib/jquery.min.js"></script>
	<script src="../lib/popper.min.js"></script>
	<script src="../lib/bootstrap.min.js"></script>
	<link href="http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic" rel="stylesheet" type="text/css">
	<meta charset="utf-8">
  
	<title>Gender Detection in the Wild</title>
	<style>

  	body {
		font-family: 'Roboto', sans-serif;
		font-size: 18px;
		font-weight: 300;
		color: #555;
		padding: 0;
	}

	.item_post{
		padding-left: 30px;
	}


	.item_post .p_title, .item_post p {
		margin: 0px;
	}

	.about_me{
		background: #f0f5f5;
	}

	.about_me .row{
		padding-top: 20px;
		padding-bottom: 20px;
	}

	#img_me{
		border: 2px solid #999;
	}

	.item_post dl{
		padding-top: 0px;
	}

  </style>

</head>
<body>
<!-- About me -->
<div class="container-fluid about_me">
	<div class="container">
		<div class="row ">
			<div class="col-sm-*">
				<h2>Real-Time Gender Detection in the Wild Using Deep Neural Networks</h2>

				<p style="text-align: justify;text-justify: inter-word"><b>Abstract:</b> Gender recognition can be used in many applications, such as video surveillance,  human-computer interaction and customized advertisement. Current state-of-the-art gender recognition methods are detector-dependent or region-dependent, focusing mostly on facial features (a face detector is typically required). These limitations do not allow an end-to-end training pipeline, and many features used in the detection phase must be re-learned in the classification step.
				Furthermore, the use of facial features limits the application of such methods in the wild, where the face might not be present. This paper presents a real-time end-to-end gender detector based on deep neural networks. The proposed method detects and recognizes the gender of persons in the wild, meaning in images with a high variability in pose, illumination an occlusions. To train and evaluate the results a new annotation set of Pascal VOC 2007 and CelebA were created. Our experimental results indicate that combining both datasets during training can increase the mAp of our gender detector. We also visually analyze which parts leads our network to make mistakes and the bias introduced by the training data.</p>

				<p><b>Authors:</b> <a href="http://luiszeni.com.br" >Luis Felipe Zeni</a> and <a href="http://inf.ufrgs.br/~crjung/" >Claudio Jung</a></p>
			</div>
		</div>
	</div>
</div>


<!-- Demos -->
<div class="container" style="margin-top:10px">
	<h2>Video Demos</h2>
	<div class="row">
		<div class="col-sm-4">
			
			<iframe  width="100%" height="200" src="https://www.youtube.com/embed/fIBuTIO9s3I?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>	
			<p style="text-align: justify;text-justify: inter-word">Real-time screen capture demo using an webcam and Nvidia GTX 1080.</p>
		</div>
		<div class="col-sm-4">
			<iframe  width="100%" height="200" src="https://www.youtube.com/embed/UYyxTpJhZEs?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>	
			<p style="text-align: justify;text-justify: inter-word">Proposed method processing a crowded video.</p>
		</div>
		<div class="col-sm-4">
			<iframe  width="100%" height="200" src="https://www.youtube.com/embed/HOd28Bszz1A?rel=0&amp;showinfo=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>	
			<p style="text-align: justify;text-justify: inter-word">Regions that the network activates during the process of gender detection.</p>
		</div>



	</div>
</div>

<!-- Code and Data -->
<div class="container" style="margin-top:0px">
	
	<div class="row">
		<div class="col-sm-*">
			<h2>Code and Data</h2>
		</div>
	</div>
<!-- Paper -->
	<div class="row item_post">
		<div class="col-sm-*">		
			<p> <b class="p_title">Paper: </b> You can download the full paper <a href="http://sibgrapi.sid.inpe.br/rep/sid.inpe.br/sibgrapi/2018/08.27.14.28?metadatarepository=sid.inpe.br/sibgrapi/2018/08.27.14.28.52&ibiurl.backgroundlanguage=en&ibiurl.requiredsite=sibgrapi.sid.inpe.br+800&requiredmirror=sid.inpe.br/banon/2001/03.30.15.38.24&searchsite=sibgrapi.sid.inpe.br:80&searchmirror=sid.inpe.br/banon/2001/03.30.15.38.24&choice=briefTitleAuthorMisc">[ here ]</a></p>
			<div style="margin-left:30px">
				<p> If you use our code or our dataset annotations in an academic work cite the following paper: </p>
				<div class="card">
<pre class="card-body">
@INPROCEEDINGS{zeni2018a,
	author={Luis Zeni and Claudio Rosito Jung}, 
	booktitle={CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES, 31. (SIBGRAPI)}, 
	title={Real-Time Gender Detection in the Wild Using Deep Neural Networks}, 
	year={2018}, 
	pages={}, 
	keywords={gender detection, deep learning, visualization}, 
	doi={}, 
	month={Oct}
}
</pre>
				</div>
			</div>
		</div>
	</div>

<!-- Annotations -->
	<div class="row item_post" style="margin-top:20px">
		<div class="col-sm-*">
			<p> <b class="p_title">Annotations: </b> In this work we adapted the <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html">Pascal VOC 2007</a> and <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a> datasets to the task of gender detection in the wild. </p>
			<div style="margin-left:30px">
				<p>Files and instructions on how to set up both datasets and they respective annotations are found <a href="https://github.com/luiszeni/sigrapi18_gender_detection/tree/master/data/annotation">[ here ]</a></p>
			</div>
		</div>
	</div>

<!-- Source Code -->
	<div class="row item_post" style="margin-top:20px">
		<div class="col-sm-*">
			<p> <b class="p_title">Source Code: </b> This work source code is available on github
			<div style="margin-left:30px">
	
					Instructions on how to set up and use our code are available on our <a href="https://github.com/luiszeni/sigrapi18_gender_detection.git">[ git repo ]</a>
			
			</div>
		</div>
	</div>

<!-- docker -->
	<div class="row item_post" style="margin-top:20px">
		<div class="col-sm-*">
			<p> <b class="p_title">Docker: </b> If you just want to test our models without lots of work configuring libs and stuff we made available an nvidia-docker with everything set up at docker hub. </p>
			<div style="margin-left:30px">
				<p> Link to the docker image <a href="https://hub.docker.com/r/luiszeni/sibgrapi18_gender_detection/">[ here ]</a></p>
				<p> Instructions of usage <a href="https://github.com/luiszeni/sibgrapi2018_gender_detection/blob/master/how_to_docker.md">[ here ]</a></p>
			</div>
		</div>
	</div>
<!-- Pre trained models -->
	<div class="row item_post" style="margin-top:20px">
		<div class="col-sm-*">
			<p> <b class="p_title">Pre-trained models: </b> You can download our pre-trained models to run on darknet or tensorflow.</p>
			<div style="margin-left:30px">
				<p> <b>Darknet:</b> 50% VOC2007 + 50% CelebA: weights - <a href="http://inf.ufrgs.br/~lfazeni/sib2018_models/gender_detection_50voc_50celeb_darknet.weights">[ weights ]</a> - <a href="https://raw.githubusercontent.com/luiszeni/sigrapi18_gender_detection/master/code/darknet/cfg/yoloGender.cfg">[ descriptors ]</a></p>
				<p> <b>TensorFlow:</b> 50% VOC2007 + 50% CelebA: - <a href="http://inf.ufrgs.br/~lfazeni/sib2018_models/gender_detection_50voc_50celeb_tensorflow.h5">[ weights ]</a> - <a href="https://github.com/luiszeni/sigrapi18_gender_detection/tree/master/code/visualization/cfg">[ descriptors ]</a></p>
			</div>
		</div>
	</div>	

</div>

<div class="container" style="margin-top:10px">
	
	<div class="row">
		<div class="col-sm-*">
			<h2>Contact</h2>
		</div>
	</div>
	<div class="row item_post" style="margin-top:0px">
		<div class="col-sm-*">
			<p>If you need more information, please feel free to contact me through the following e-mail:</p>
			<p> <b>luis [dot] zeni [at] inf [dot] ufrgs [dot] br </b></p>
		</div>
	</div>
</div>

<div class="container" style="margin-top:10px">
	<div class="row">
		<div class="col-sm-*">
			<h2>Acknowledgment</h2>
		</div>
	</div>
	<div class="row item_post" style="margin-top:0px">
		<div class="col-sm-*">
			<p>We would like to thank the Brazilian funding agencies <a href="http://www.capes.gov.br/">CAPES</a> and <a href="http://www.cnpq.br/">CNPq</a>. As well as NVIDIA Corporation for the donation of the Titan Xp Pascal GPU used for this research.</p>
		</div>
	</div>
</div>

<footer class="container-fluid text-center about_me" style="margin-top: 30px">
  	<div class="row" style="height: 100px">

  	</div>
</footer>

</body>
</html>
